{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import gpflow\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.style.use('ggplot')\n",
    "mpl.rcParams['pgf.rcfonts'] = False\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "\n",
    "from gp_svgp import GP_MNIST_SVGP\n",
    "from mnist_cnn import CNN_MNIST\n",
    "from mnist_svm import SVM_MNIST\n",
    "from hybrid_mnist import Hybrid_MNIST\n",
    "from mnist_preprocessing import get_mnist_data\n",
    "\n",
    "#from plotting import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'standard': {\n",
    "        'accuracy': {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard MNIST test data\n",
    "((_, mnist_test_imgs), (ys_train_onehot, ys_test_onehot)) = get_mnist_data()\n",
    "mnist_train_features = np.genfromtxt(\"../data/mnist_train_features.csv\", delimiter=\",\")\n",
    "mnist_test_features = np.genfromtxt(\"../data/mnist_test_features.csv\", delimiter=\",\")\n",
    "\n",
    "ys_train = np.argmax(ys_train_onehot, axis=1)\n",
    "ys_test = np.argmax(ys_test_onehot, axis=1)\n",
    "# easier to remember handle\n",
    "correct_classes = ys_test\n",
    "n = len(ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN_MNIST(isolate=True) # isolate sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVM_MNIST(mnist_train_features, ys_train, nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_models = []\n",
    "for tol in np.arange(0, 2.0, 0.5):\n",
    "    hybrid_models.append(Hybrid_MNIST(accept_cnn_tolerance = tol))\n",
    "for tol in np.arange(0, 2.0, 0.5):\n",
    "    hybrid_models.append(Hybrid_MNIST(accept_cnn_tolerance = tol, stronger_criterion=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 4515.149993\n",
      "  Number of iterations: 11\n",
      "  Number of functions evaluations: 20\n"
     ]
    }
   ],
   "source": [
    "# instantiate models we want to test\n",
    "# only one at a time here to avoid interference\n",
    "\n",
    "gp_model = GP_MNIST_SVGP(kernel=gpflow.kernels.Linear, \n",
    "                         whitevar=0.1,\n",
    "                         latent_split=20,\n",
    "                         whiten=True,\n",
    "                         q_diag=True,\n",
    "                         minibatch=8000,\n",
    "                         whitevar_trainable=False,\n",
    "                         feat_trainable=True,\n",
    "                         name=\"Linear Kernel GP\")\n",
    "\n",
    "# gp_model = GP_MNIST_SVGP(kernel=gpflow.kernels.Matern12, \n",
    "#                          whitevar=0.1,\n",
    "#                          latent_split=20,\n",
    "#                          whiten=True,\n",
    "#                          q_diag=True,\n",
    "#                          minibatch=8000,\n",
    "#                          whitevar_trainable=False,\n",
    "#                          feat_trainable=True,\n",
    "#                          name=\"Matern12 Kernel GP\")\n",
    "\n",
    "# gp_model = GP_MNIST_SVGP(kernel=gpflow.kernels.Matern32, \n",
    "#                          whitevar=0.1,\n",
    "#                          latent_split=20,\n",
    "#                          whiten=True,\n",
    "#                          q_diag=True,\n",
    "#                          minibatch=8000,\n",
    "#                          whitevar_trainable=False,\n",
    "#                          feat_trainable=True,\n",
    "#                          name=\"Matern32 Kernel GP\")\n",
    "\n",
    "# gp_model = GP_MNIST_SVGP(kernel=gpflow.kernels.Matern32, \n",
    "#                          whitevar=0.1,\n",
    "#                          latent_split=20,\n",
    "#                          whiten=True,\n",
    "#                          q_diag=True,\n",
    "#                          minibatch=8000,\n",
    "#                          whitevar_trainable=False,\n",
    "#                          feat_trainable=True,\n",
    "#                          name=\"Matern52 Kernel GP\")\n",
    "\n",
    "# gp_model = GP_MNIST_SVGP(kernel=gpflow.kernels.RBF, \n",
    "#                          whitevar=0.1,\n",
    "#                          latent_split=20,\n",
    "#                          whiten=True,\n",
    "#                          q_diag=True,\n",
    "#                          minibatch=8000,\n",
    "#                          whitevar_trainable=False,\n",
    "#                          feat_trainable=True,\n",
    "#                          name=\"RBF Kernel GP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (10000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e74bcb35e509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmnist_cnn_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_img_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_test_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmnist_cnn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_cnn_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmnist_cnn_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_cnn_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/pml/CNN_GP_MNIST/src/mnist_cnn.py\u001b[0m in \u001b[0;36mpredict_img_batch\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0mcnn_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mcnn_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;31m#cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1497\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1498\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (10000, 28, 28)"
     ]
    }
   ],
   "source": [
    "record_in = 'Standard MNIST'\n",
    "\n",
    "# prediction accuracies\n",
    "subkey = 'accuracy'\n",
    "\n",
    "#CNN\n",
    "mnist_cnn_preds = cnn_model.predict_img_batch(mnist_test_imgs)\n",
    "mnist_cnn_classes = np.argmax(mnist_cnn_preds, axis=1)\n",
    "mnist_cnn_correct = correct_classes = mnist_cnn_classes\n",
    "data[record_in][subkey][cnn_model.name] = mnist_cnn_correct / n\n",
    "\n",
    "# SVM\n",
    "mnist_svm_classes = svm_model.predict_batch(mnist_test_features)\n",
    "mnist_svm_correct = correct_classes = mnist_svm_classes\n",
    "data[record_int][subkey][svm_model.name] = mnist_svm_correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP\n",
    "mnist_gp_mu, mnist_gp_var = gp_model.predict_batch(mnist_test_features)\n",
    "mnist_gp_classes = np.argmax(mnist_gp_mu, axis=1)\n",
    "mnist_gp_correct = correct_classes = mnist_gp_classes\n",
    "data[record_in][subkey][gp_model.name] = mnist_cnn_correct / n\n",
    "\n",
    "for hybrid in hybrid_models:\n",
    "    name = hybrid.name + \"(GP: {})\".format(gp_model.name)\n",
    "    hybrid_pred, hybrid_mus, hybrid_vars = combined_predict_efficient(mnist_cnn_preds, mnist_gp_mu, mnist_gp_var)\n",
    "    hybrid_classes = hybrid_pred[:, 1]\n",
    "    hybrid_correct = correct_classes = hybrid_classes\n",
    "    data[record_in][subkey][name] = hybrid_correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point we can settle on one or two GP + 4 hybrid variants\n",
    "\n",
    "# Preprocess the N-MNIST data just like standard MNIST\n",
    "nmnist_noisy = scipy.io.loadmat('../data/raw/n-mnist/nmnist-awgn.mat')\n",
    "\n",
    "record_in = 'MNIST + White noise'\n",
    "if record_in not in data:\n",
    "    data[record_in] = {} \n",
    "# noisy\n",
    "subkey = 'Accuracy'\n",
    "if subkey not in data[record_in]:\n",
    "    data[record_in][subkey] = {}\n",
    "    \n",
    "\n",
    "noisy_feats = mnist_cnn.extract_features(nmnist_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmnist_blur = scipy.io.loadmat('../data/raw/n-mnist/nmnist-blur.mat')\n",
    "record_in = 'Blurry MNIST'\n",
    "if record_in not in data:\n",
    "    data[record_in] = {} \n",
    "# noisy\n",
    "subkey = 'Accuracy'\n",
    "if subkey not in data[record_in]:\n",
    "    data[record_in][subkey] = {}\n",
    "    \n",
    "blur_feats = mnist_cnn.extract_features(nmnist_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmnist_noisy_lowcontrast = scipy.io.loadmat('../data/raw/n-mnist/nmnist-contrast.mat')\n",
    "record_in = 'Low Contrast MNIST'\n",
    "if record_in not in data:\n",
    "    data[record_in] = {} \n",
    "# noisy\n",
    "subkey = 'Accuracy'\n",
    "if subkey not in data[record_in]:\n",
    "    data[record_in][subkey] = {}\n",
    "    \n",
    "lowcontrast_feats = mnist_cnn.extract_features(nmnist_noisy_lowcontrast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
