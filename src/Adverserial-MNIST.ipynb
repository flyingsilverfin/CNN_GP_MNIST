{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "xs_train_full = np.genfromtxt(\"../data/mnist_train_features.csv\", delimiter=\",\")\n",
    "xs_test_full = np.genfromtxt(\"../data/mnist_test_features.csv\", delimiter=\",\")\n",
    "\n",
    "def get_mnist_classes():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return ((x_train, x_test), (y_train, y_test))\n",
    "\n",
    "((mnist_train_full, mnist_test_full), (ys_train_full, ys_test_full)) = get_mnist_classes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 128 features, predicting 10 classes\n"
     ]
    }
   ],
   "source": [
    "# fitting entirety of model on base MNIST data\n",
    "\n",
    "num_features = xs_train_full.shape[-1]\n",
    "num_classes = 10\n",
    "print(\"Using\", num_features, \"features, predicting\", num_classes, \"classes\")\n",
    "\n",
    "ys = np.argmax(ys_train_full, axis=1)\n",
    "\n",
    "# remove the default one just in case\n",
    "gpflow.get_session().close()\n",
    "sess = tf.Session()\n",
    "sess.as_default()\n",
    "\n",
    "gp_model = gpflow.models.SVGP(\n",
    "    xs_train_full, ys, kern=gpflow.kernels.Matern12(input_dim=num_features) + gpflow.kernels.White(input_dim=num_features, variance=0.5),\n",
    "    likelihood=gpflow.likelihoods.MultiClass(num_classes),\n",
    "    Z=xs_train_full[::25].copy(), \n",
    "    num_latent=num_classes, \n",
    "    whiten=True, \n",
    "    q_diag=True,\n",
    "    minibatch_size=8000)\n",
    "#gp_model.kern.white.variance.trainable = False\n",
    "#gp_model.feature.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 6798.916416\n",
      "  Number of iterations: 17\n",
      "  Number of functions evaluations: 33\n"
     ]
    }
   ],
   "source": [
    "opt = gpflow.train.ScipyOptimizer()\n",
    "opt.minimize(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, var) = gp_model.predict_y(xs_test_full)\n",
    "gp_predicted_classes = np.argmax(mu, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_classes = np.argmax(ys_test_full, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GP incorrect:  95\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GP incorrect: \", np.count_nonzero(gp_predicted_classes != correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "\n",
    "mnist_test_full_reshape = mnist_test_full_reshape.astype('float32')\n",
    "mnist_test_full_reshape /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor '25/SVGP/q_sqrt/initial_unconstrained_value' with dtype double and shape [2400,10]\n\t [[Node: 25/SVGP/q_sqrt/initial_unconstrained_value = Placeholder[dtype=DT_DOUBLE, shape=[2400,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op '25/SVGP/q_sqrt/initial_unconstrained_value', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-407d76f965bc>\", line 9, in <module>\n    minibatch_size=8000)\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/core/compilable.py\", line 90, in __init__\n    self.build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/core/node.py\", line 172, in build\n    self._build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/models/model.py\", line 80, in _build\n    super(Model, self)._build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/params/parameterized.py\", line 284, in _build\n    param.build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/core/node.py\", line 172, in build\n    self._build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/params/parameter.py\", line 345, in _build\n    unconstrained = self._build_parameter()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/params/parameter.py\", line 367, in _build_parameter\n    init = tf.placeholder(self.dtype, shape=shape, name='initial_unconstrained_value')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor '25/SVGP/q_sqrt/initial_unconstrained_value' with dtype double and shape [2400,10]\n\t [[Node: 25/SVGP/q_sqrt/initial_unconstrained_value = Placeholder[dtype=DT_DOUBLE, shape=[2400,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor '25/SVGP/q_sqrt/initial_unconstrained_value' with dtype double and shape [2400,10]\n\t [[Node: 25/SVGP/q_sqrt/initial_unconstrained_value = Placeholder[dtype=DT_DOUBLE, shape=[2400,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cd8123124af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just to be sure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmnist_cnn_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../models/mnist_cnn.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Keras approach!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor '25/SVGP/q_sqrt/initial_unconstrained_value' with dtype double and shape [2400,10]\n\t [[Node: 25/SVGP/q_sqrt/initial_unconstrained_value = Placeholder[dtype=DT_DOUBLE, shape=[2400,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op '25/SVGP/q_sqrt/initial_unconstrained_value', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-407d76f965bc>\", line 9, in <module>\n    minibatch_size=8000)\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/core/compilable.py\", line 90, in __init__\n    self.build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/core/node.py\", line 172, in build\n    self._build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/models/model.py\", line 80, in _build\n    super(Model, self)._build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/params/parameterized.py\", line 284, in _build\n    param.build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/core/node.py\", line 172, in build\n    self._build()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/params/parameter.py\", line 345, in _build\n    unconstrained = self._build_parameter()\n  File \"/local/scratch/js2173/venv/lib/python3.5/site-packages/gpflow/params/parameter.py\", line 367, in _build_parameter\n    init = tf.placeholder(self.dtype, shape=shape, name='initial_unconstrained_value')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor '25/SVGP/q_sqrt/initial_unconstrained_value' with dtype double and shape [2400,10]\n\t [[Node: 25/SVGP/q_sqrt/initial_unconstrained_value = Placeholder[dtype=DT_DOUBLE, shape=[2400,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "K.get_session().close() # just to be sure\n",
    "\n",
    "mnist_cnn_path = '../models/mnist_cnn.h5'\n",
    "\n",
    "# Keras approach!\n",
    "cnn_test_probs = None\n",
    "# release graph resources when done otherwise inconsistent results\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session().as_default() as sess:\n",
    "        K.set_session(sess)\n",
    "        mnist_cnn = keras.models.load_model(mnist_cnn_path)\n",
    "        cnn_test_probs = mnist_cnn.predict_on_batch(mnist_test_full_reshape)\n",
    "        cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\n",
    "        print(\"Num CNN incorrect:\", np.count_nonzero(cnn_predicted_classes != correct_classes))\n",
    "        K.get_session().close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF approach!\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        K.set_learning_phase(0) #set learning phase to test!\n",
    "        # get the full CNN\n",
    "        mnist_cnn = keras.models.load_model(mnist_cnn_path)\n",
    "        \n",
    "        x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "        cnn_preds_placeholder = mnist_cnn(x)\n",
    "\n",
    "        cnn_test_probs = cnn_preds_placeholder.eval(feed_dict={x: mnist_test_full_reshape})\n",
    "        \n",
    "        cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\n",
    "        print(\"Num CNN incorrect:\", np.count_nonzero(cnn_predicted_classes != correct_classes))\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "\n",
    "\"\"\" \n",
    "params:\n",
    "    cnn_probs\n",
    "    gp_probs,\n",
    "    gp_vars,\n",
    "    verbose,\n",
    "    accept_cnn_stddev\n",
    "\"\"\"\n",
    "\n",
    "def combined_predict_efficient(cnn_probs_all, gp_mu, gp_var, verbose=False, accept_cnn_stddev = 1.0):\n",
    "    assert (cnn_probs_all.shape[0] == gp_mu.shape[0] == gp_var.shape[0])\n",
    "    decisions = []\n",
    "    decision_probs = []\n",
    "    decision_vars = []\n",
    "    for (mu, var, cnn_probs) in zip(gp_mu, gp_var, cnn_probs_all):\n",
    "        cnn_class = np.argmax(cnn_probs)\n",
    "        gp_class = np.argmax(mu)\n",
    "        \n",
    "        gp_pred_prob = mu[gp_class]\n",
    "        gp_pred_var = var[gp_class]\n",
    "        \n",
    "        cnn_pred_prob = cnn_probs[cnn_class]\n",
    "        \n",
    "        # both classes agree\n",
    "        if gp_class == cnn_class:\n",
    "            # we may have to accept the wrong decision but can't do anything about it\n",
    "            #if verbose:\n",
    "            #    print(\"Models agree on predicted class\")\n",
    "            decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "            decision_probs.append(mu)\n",
    "            decision_vars.append(var)\n",
    "        else:\n",
    "            # disagreement! This is additional information\n",
    "            # From prior experiments we suspect that NN is more likely to be correct [non-adverserial examples tested]\n",
    "            # So, if we take the CNN prediction and check if it's the same as the _second_ highest GP prediction\n",
    "            # try using that?\n",
    "\n",
    "            # Revised:\n",
    "            #  Take the CNN prediction IF it's probability is within 1 stddev of the corresponding GP class probability\n",
    "\n",
    "            # core idea: if CNN is _too_ sure then we revert to GP prediction -- might be adverserial...?\n",
    "\n",
    "            gp_prob_for_cnn_pred = mu[cnn_class]\n",
    "            gp_stddev_for_cnn_pred = np.sqrt(var[cnn_class])\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Models disagree on predicted class\")\n",
    "\n",
    "            if cnn_pred_prob < (gp_prob_for_cnn_pred + accept_cnn_stddev*gp_stddev_for_cnn_pred):\n",
    "                if verbose:\n",
    "                    print(\"  Taking CNN prediction, probability is within\", accept_cnn_stddev, \"stddev of GP probability\")\n",
    "                decisions.append([1, cnn_class, cnn_pred_prob, -1])\n",
    "                decision_probs.append(cnn_probs)\n",
    "                decision_vars.append([-1 for x in range(mu.shape[-1])])\n",
    "\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"  Taking GP prediction\")\n",
    "                decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "                decision_probs.append(mu)\n",
    "                decision_vars.append(var)\n",
    "    return (np.array(decisions), np.array(decision_probs), np.array(decision_vars))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "params:\n",
    "    cnn_path: trained mnist CNN file path\n",
    "    gp: trained gaussian process for multiclass classification\n",
    "    verbose: printing on/off \n",
    "    accept_cnn_stddev: if CNN predicted class has higher prob than GP's, this is number of stddevs the CNN prediction needs to be within from the GP prediction to acccept it\n",
    "        ie. higher = more likely to revert to CNN!\n",
    "\"\"\"\n",
    "def combined_predict(cnn_path, gp, images, verbose=False, accept_cnn_stddev=1):\n",
    "    # so my CNN can only predict on batches of 4 or greater...\n",
    "    if images.shape[0] < 4:\n",
    "        print(\"Can only predict with >= 4 images at a time\")\n",
    "        return\n",
    "    batch = images\n",
    "    \n",
    "    cnn_probs_batch = None\n",
    "    features = None\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default():\n",
    "            mnist_cnn = keras.models.load_model(cnn_path)\n",
    "            cnn_probs_batch = mnist_cnn.predict_on_batch(batch)\n",
    "    \n",
    "            # need to get output of second to last layer in CNN to feed into GP\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Extracting features from second to last layer of CNN\")\n",
    "            feature_extractor = K.function([mnist_cnn.layers[0].input, K.learning_phase()],\n",
    "                                           [mnist_cnn.layers[-2].output])\n",
    "            features = feature_extractor([images, 0])[0]\n",
    "    \n",
    "    gp_mu, gp_var = gp.predict_y(features)\n",
    "\n",
    "    \n",
    "    decisions = []\n",
    "    decision_probs = []\n",
    "    decision_vars = []\n",
    "    for (mu, var, cnn_probs) in zip(gp_mu, gp_var, cnn_probs_batch):\n",
    "        cnn_class = np.argmax(cnn_probs)\n",
    "        gp_class = np.argmax(mu)\n",
    "        \n",
    "        gp_pred_prob = mu[gp_class]\n",
    "        gp_pred_var = var[gp_class]\n",
    "        \n",
    "        cnn_pred_prob = cnn_probs[cnn_class]\n",
    "        \n",
    "        # both classes agree\n",
    "        if gp_class == cnn_class:\n",
    "            # we may have to accept the wrong decision but can't do anything about it\n",
    "            #if verbose:\n",
    "            #    print(\"Models agree on predicted class\")\n",
    "            decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "            decision_probs.append(mu)\n",
    "            decision_vars.append(var)\n",
    "\n",
    "        else:\n",
    "            # disagreement! This is additional information\n",
    "            # From prior experiments we suspect that NN is more likely to be correct [non-adverserial examples tested]\n",
    "            # So, if we take the CNN prediction and check if it's the same as the _second_ highest GP prediction\n",
    "            # try using that?\n",
    "\n",
    "            # Revised:\n",
    "            #  Take the CNN prediction IF it's probability is within 1 stddev of the corresponding GP class probability\n",
    "\n",
    "            # core idea: if CNN is _too_ sure then we revert to GP prediction -- might be adverserial...?\n",
    "\n",
    "            gp_prob_for_cnn_pred = mu[cnn_class]\n",
    "            gp_stddev_for_cnn_pred = np.sqrt(var[cnn_class])\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Models disagree on predicted class\")\n",
    "\n",
    "            if cnn_pred_prob < (gp_prob_for_cnn_pred + accept_cnn_stddev*gp_stddev_for_cnn_pred):\n",
    "                if verbose:\n",
    "                    print(\"  Taking CNN prediction, probability is within\", accept_cnn_stddev, \"stddev of GP probability\")\n",
    "                decisions.append([1, cnn_class, cnn_pred_prob, -1])\n",
    "                decision_probs.append(cnn_probs)\n",
    "                decision_vars.append([-1 for x in range(mu.shape[-1])])\n",
    "\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"  Taking GP prediction\")\n",
    "                decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "                decision_probs.append(mu)\n",
    "                decision_vars.append(var)\n",
    "    return (np.array(decisions), np.array(decision_probs), np.array(decision_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_pred, combined_mus, combined_vars = combined_predict(cnn_path=\"../models/mnist_cnn.h5\", gp=gp_model, images=mnist_test_full_reshape, accept_cnn_stddev=1.0)\n",
    "combined_pred, combined_mus, combined_vars = combined_predict_efficient(cnn_test_probs, mu, var, accept_cnn_stddev=1.0)\n",
    "combined_pred_classes = combined_pred[:, 1]\n",
    "combined_incorrect = combined_pred_classes != correct_classes\n",
    "print(\"Num Combined incorrect: \", np.count_nonzero(combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have all 3 models available now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_keras import cnn_model\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "\n",
    "\n",
    "#adv_predictions = None\n",
    "#perturbed = None\n",
    "def perturb_images(model_path, data, eps=0.2, ):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        with tf.Session().as_default() as sess:\n",
    "            K.set_learning_phase(0) #set learning phase\n",
    "\n",
    "            #make a fresh copy to not modify other graph\n",
    "            model = keras.models.load_model(model_path)\n",
    "\n",
    "            x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "            y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "            # Initialize the Fast Gradient Sign Method (FGSM) attack object and graph\n",
    "            wrap = KerasModelWrapper(model)\n",
    "            fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "            fgsm_params = {'eps': eps,\n",
    "                           'clip_min': 0.,\n",
    "                           'clip_max': 1.}\n",
    "            adv_x = fgsm.generate(x, **fgsm_params)\n",
    "            # Consider the attack to be constant\n",
    "            adv_x = tf.stop_gradient(adv_x)\n",
    "            preds_adv = model(adv_x)\n",
    "\n",
    "            adv_predictions = sess.run(preds_adv, {x: data})\n",
    "            perturbed = sess.run(adv_x, {x: data})\n",
    "            \n",
    "            return (adv_predictions, perturbed)\n",
    "        \n",
    "adv_predictions, perturbed = perturb_images(mnist_cnn_path, mnist_test_full_reshape, eps=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist(x, ys, one_hot_encode=-1):\n",
    "    xs = x.copy()\n",
    "    img_rows, img_cols = 28, 28    \n",
    "    # reshape to inputs to correct shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        xs = xs.reshape(xs.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        xs = xs.reshape(xs.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    xs = xs.astype('float32')\n",
    "    xs /= 255\n",
    "    \n",
    "    if one_hot_encode != -1:\n",
    "        ys = keras.utils.to_categorical(ys, one_hot_encode) # one_hot_encode is the number of classes\n",
    "    \n",
    "    return (xs, ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(model_path, images):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default() as sess:\n",
    "            K.set_session(sess)\n",
    "            K.set_learning_phase(0) #set learning phase\n",
    "\n",
    "            #make a fresh copy to not modify other graph\n",
    "            model = keras.models.load_model(model_path)\n",
    "            feature_extractor = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                           [model.layers[6].output])\n",
    "            #pert, ys = preprocess_mnist(perturbed, ys_test_full)\n",
    "            #print(pert.shape)\n",
    "            return feature_extractor([images])[0]\n",
    "\n",
    "adv_fsgm_features = extract_features(mnist_cnn_path, perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gpflow.session_manager.get_session().as_default():\n",
    "(adv_mu, adv_var) = gp_model.predict_y(adv_fsgm_features)\n",
    "adv_gp_preds = np.argmax(adv_mu, axis=1)\n",
    "print(\"GP fsgm adversarial incorrect: \", np.count_nonzero(correct_classes != adv_gp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_combined_pred, adv_combined_mus, adv_combined_vars = combined_predict(cnn_path=\"../models/mnist_cnn.h5\", gp=gp_model, images=perturbed, accept_cnn_stddev=1.5)\n",
    "adv_combined_pred_classes = adv_combined_pred[:, 1]\n",
    "adv_combined_incorrect = adv_combined_pred_classes != correct_classes\n",
    "print(\"Num Combined incorrect: \", np.count_nonzero(adv_combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epsilons = np.arange(0, 0.4, 0.025)\n",
    "# stddev_accepts = np.arange(0.0, 2.5, 0.25)\n",
    "\n",
    "# for eps in epsilons:\n",
    "#     adv_cnn_predictions, perturbed = perturb_images(mnist_cnn_path, mnist_test_full_reshape, eps=eps)\n",
    "#     adv_cnn_classes = np.argmax(adv_cnn_predictions, axis=1)\n",
    "    \n",
    "#     #print(\"Incorrect: \", np.count_nonzero(correct_classes != adv_cnn_classes))\n",
    "\n",
    "#     adv_fsgm_features = extract_features(mnist_cnn_path)\n",
    "#     (adv_mu, adv_var) = gp_model.predict_y(adv_fsgm_features)\n",
    "#     adv_gp_preds = np.argmax(adv_mu, axis=1)\n",
    "        \n",
    "#     adv_cnn_correct = adv_cnn_classes == correct_classes\n",
    "#     adv_gp_correct = adv_gp_preds == correct_classes\n",
    "    \n",
    "#     n = len(correct_classes)\n",
    "    \n",
    "#     print(\"Epsilon =\", eps)\n",
    "#     print(\"  CNN accuracy: \", np.count_nonzero(adv_cnn_correct) / n)\n",
    "#     print(\"  GP accuracy: \", np.count_nonzero(adv_gp_correct) / n)\n",
    "    \n",
    "#     for stddev_accept in stddev_accepts:\n",
    "#         adv_combined_pred, adv_combined_mus, adv_combined_vars = combined_predict_efficient(adv_cnn_predictions, adv_mu, adv_var, accept_cnn_stddev=stddev_accept)\n",
    "\n",
    "#         adv_combined_pred_classes = adv_combined_pred[:, 1]\n",
    "#         adv_combined_correct = adv_combined_pred_classes == correct_classes\n",
    "\n",
    "#         print(\"  Combined accuracy (accept = \", stddev_accept, \"): \", np.count_nonzero(adv_combined_correct) / n)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM for comparison as well\n",
    "from sklearn import svm\n",
    "mnist_svm = svm.SVC(decision_function_shape='ovo', probability=True)\n",
    "ys = np.argmax(ys_train_full, axis=1) # no need for 1-hot encoding\n",
    "mnist_svm.fit(xs_train_full, ys) \n",
    "\n",
    "#pred = clf.predict(xs_test_full)\n",
    "#print(pred)\n",
    "#print(\"SVM correct classificaitons: \",  np.count_nonzero(pred != correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epsilons = np.arange(0, 0.4, 0.025)\n",
    "stddev_accepts = np.arange(0.0, 2.5, 0.25)\n",
    "stddev_keep = [0.5, 1.0]\n",
    "\n",
    "n = len(correct_classes)\n",
    "\n",
    "def acc(correct):\n",
    "    return np.count_nonzero(correct) / n\n",
    "    \n",
    "accuracies = []\n",
    "for eps in epsilons:\n",
    "    adv_cnn_predictions, perturbed = perturb_images(mnist_cnn_path, mnist_test_full_reshape, eps=eps)\n",
    "    adv_cnn_classes = np.argmax(adv_cnn_predictions, axis=1)\n",
    "    \n",
    "    #print(\"Incorrect: \", np.count_nonzero(correct_classes != adv_cnn_classes))\n",
    "\n",
    "    adv_fsgm_features = extract_features(mnist_cnn_path, perturbed)\n",
    "    (adv_mu, adv_var) = gp_model.predict_y(adv_fsgm_features)\n",
    "    adv_gp_preds = np.argmax(adv_mu, axis=1)\n",
    "        \n",
    "    adv_cnn_correct = adv_cnn_classes == correct_classes\n",
    "    adv_gp_correct = adv_gp_preds == correct_classes\n",
    "    \n",
    "    adv_svm_preds = mnist_svm.predict(adv_fsgm_features)\n",
    "    adv_svm_correct = adv_svm_preds == correct_classes\n",
    "    \n",
    "    \n",
    "    print(\"Epsilon =\", eps)\n",
    "    print(\"  CNN accuracy: \", acc(adv_cnn_correct))\n",
    "    print(\"  GP accuracy: \", acc(adv_gp_correct))\n",
    "    print(\"  SVM accuracy: \", acc(adv_svm_correct))\n",
    "    \n",
    "    accuracies.append([acc(adv_cnn_correct), acc(adv_gp_correct), acc(adv_svm_correct)])\n",
    "    for stddev_accept in stddev_accepts:\n",
    "        adv_combined_pred, adv_combined_mus, adv_combined_vars = combined_predict_efficient(adv_cnn_predictions, adv_mu, adv_var, accept_cnn_stddev=stddev_accept)\n",
    "\n",
    "        adv_combined_pred_classes = adv_combined_pred[:, 1]\n",
    "        adv_combined_correct = adv_combined_pred_classes == correct_classes\n",
    "\n",
    "        print(\"  Combined accuracy (accept = \", stddev_accept, \"): \", acc(adv_combined_correct))\n",
    "        if stddev_accept in stddev_keep:\n",
    "            accuracies[-1].append(acc(adv_combined_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
