{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "xs_train_full = np.genfromtxt(\"../data/mnist_train_features.csv\", delimiter=\",\")\n",
    "xs_test_full = np.genfromtxt(\"../data/mnist_test_features.csv\", delimiter=\",\")\n",
    "\n",
    "def get_mnist_classes():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return ((x_train, x_test), (y_train, y_test))\n",
    "\n",
    "((mnist_train_full, mnist_test_full), (ys_train_full, ys_test_full)) = get_mnist_classes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 128 features, predicting 10 classes\n"
     ]
    }
   ],
   "source": [
    "# fitting entirety of model on base MNIST data\n",
    "\n",
    "num_features = xs_train_full.shape[-1]\n",
    "num_classes = 10\n",
    "print(\"Using\", num_features, \"features, predicting\", num_classes, \"classes\")\n",
    "\n",
    "ys = np.argmax(ys_train_full, axis=1)\n",
    "\n",
    "# remove the default one just in case\n",
    "gpflow.get_session().close()\n",
    "sess = tf.Session()\n",
    "sess.as_default()\n",
    "\n",
    "gp_model = gpflow.models.SVGP(\n",
    "    xs_train_full, ys, kern=gpflow.kernels.Matern12(input_dim=num_features) + gpflow.kernels.White(input_dim=num_features, variance=0.5),\n",
    "    likelihood=gpflow.likelihoods.MultiClass(num_classes),\n",
    "    Z=xs_train_full[::25].copy(), \n",
    "    num_latent=num_classes, \n",
    "    whiten=True, \n",
    "    q_diag=True,\n",
    "    minibatch_size=8000)\n",
    "#gp_model.kern.white.variance.trainable = False\n",
    "#gp_model.feature.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 6798.916460\n",
      "  Number of iterations: 17\n",
      "  Number of functions evaluations: 33\n"
     ]
    }
   ],
   "source": [
    "opt = gpflow.train.ScipyOptimizer()\n",
    "opt.minimize(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, var) = gp_model.predict_y(xs_test_full)\n",
    "gp_predicted_classes = np.argmax(mu, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_classes = np.argmax(ys_test_full, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GP incorrect:  95\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GP incorrect: \", np.count_nonzero(gp_predicted_classes != correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "\n",
    "mnist_test_full_reshape = mnist_test_full_reshape.astype('float32')\n",
    "mnist_test_full_reshape /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CNN incorrect: 89\n"
     ]
    }
   ],
   "source": [
    "K.get_session().close() # just to be sure\n",
    "\n",
    "mnist_cnn_path = '../models/mnist_cnn.h5'\n",
    "\n",
    "# Keras approach!\n",
    "cnn_test_probs = None\n",
    "# release graph resources when done otherwise inconsistent results\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session().as_default() as sess:\n",
    "        K.set_session(sess)\n",
    "        mnist_cnn = keras.models.load_model(mnist_cnn_path)\n",
    "        cnn_test_probs = mnist_cnn.predict_on_batch(mnist_test_full_reshape)\n",
    "        cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\n",
    "        print(\"Num CNN incorrect:\", np.count_nonzero(cnn_predicted_classes != correct_classes))\n",
    "        K.get_session().close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CNN incorrect: 89\n"
     ]
    }
   ],
   "source": [
    "# TF approach!\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        K.set_learning_phase(0) #set learning phase to test!\n",
    "        # get the full CNN\n",
    "        mnist_cnn = keras.models.load_model(mnist_cnn_path)\n",
    "        \n",
    "        x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "        cnn_preds_placeholder = mnist_cnn(x)\n",
    "\n",
    "        cnn_test_probs = cnn_preds_placeholder.eval(feed_dict={x: mnist_test_full_reshape})\n",
    "        \n",
    "        cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\n",
    "        print(\"Num CNN incorrect:\", np.count_nonzero(cnn_predicted_classes != correct_classes))\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "\n",
    "\"\"\" \n",
    "params:\n",
    "    cnn_probs\n",
    "    gp_probs,\n",
    "    gp_vars,\n",
    "    verbose,\n",
    "    accept_cnn_stddev\n",
    "\"\"\"\n",
    "\n",
    "def combined_predict_efficient(cnn_probs_all, gp_mu, gp_var, verbose=False, accept_cnn_stddev = 1.0):\n",
    "    assert (cnn_probs_all.shape[0] == gp_mu.shape[0] == gp_var.shape[0])\n",
    "    decisions = []\n",
    "    decision_probs = []\n",
    "    decision_vars = []\n",
    "    for (mu, var, cnn_probs) in zip(gp_mu, gp_var, cnn_probs_all):\n",
    "        cnn_class = np.argmax(cnn_probs)\n",
    "        gp_class = np.argmax(mu)\n",
    "        \n",
    "        gp_pred_prob = mu[gp_class]\n",
    "        gp_pred_var = var[gp_class]\n",
    "        \n",
    "        cnn_pred_prob = cnn_probs[cnn_class]\n",
    "        \n",
    "        # both classes agree\n",
    "        if gp_class == cnn_class:\n",
    "            # we may have to accept the wrong decision but can't do anything about it\n",
    "            #if verbose:\n",
    "            #    print(\"Models agree on predicted class\")\n",
    "            decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "            decision_probs.append(mu)\n",
    "            decision_vars.append(var)\n",
    "        else:\n",
    "            # disagreement! This is additional information\n",
    "            # From prior experiments we suspect that NN is more likely to be correct [non-adverserial examples tested]\n",
    "            # So, if we take the CNN prediction and check if it's the same as the _second_ highest GP prediction\n",
    "            # try using that?\n",
    "\n",
    "            # Revised:\n",
    "            #  Take the CNN prediction IF it's probability is within 1 stddev of the corresponding GP class probability\n",
    "\n",
    "            # core idea: if CNN is _too_ sure then we revert to GP prediction -- might be adverserial...?\n",
    "\n",
    "            gp_prob_for_cnn_pred = mu[cnn_class]\n",
    "            gp_stddev_for_cnn_pred = np.sqrt(var[cnn_class])\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Models disagree on predicted class\")\n",
    "\n",
    "            if cnn_pred_prob < (gp_prob_for_cnn_pred + accept_cnn_stddev*gp_stddev_for_cnn_pred):\n",
    "                if verbose:\n",
    "                    print(\"  Taking CNN prediction, probability is within\", accept_cnn_stddev, \"stddev of GP probability\")\n",
    "                decisions.append([1, cnn_class, cnn_pred_prob, -1])\n",
    "                decision_probs.append(cnn_probs)\n",
    "                decision_vars.append([-1 for x in range(mu.shape[-1])])\n",
    "\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"  Taking GP prediction\")\n",
    "                decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "                decision_probs.append(mu)\n",
    "                decision_vars.append(var)\n",
    "    return (np.array(decisions), np.array(decision_probs), np.array(decision_vars))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "params:\n",
    "    cnn_path: trained mnist CNN file path\n",
    "    gp: trained gaussian process for multiclass classification\n",
    "    verbose: printing on/off \n",
    "    accept_cnn_stddev: if CNN predicted class has higher prob than GP's, this is number of stddevs the CNN prediction needs to be within from the GP prediction to acccept it\n",
    "        ie. higher = more likely to revert to CNN!\n",
    "\"\"\"\n",
    "def combined_predict(cnn_path, gp, images, verbose=False, accept_cnn_stddev=1):\n",
    "    # so my CNN can only predict on batches of 4 or greater...\n",
    "    if images.shape[0] < 4:\n",
    "        print(\"Can only predict with >= 4 images at a time\")\n",
    "        return\n",
    "    batch = images\n",
    "    \n",
    "    cnn_probs_batch = None\n",
    "    features = None\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default():\n",
    "            mnist_cnn = keras.models.load_model(cnn_path)\n",
    "            cnn_probs_batch = mnist_cnn.predict_on_batch(batch)\n",
    "    \n",
    "            # need to get output of second to last layer in CNN to feed into GP\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Extracting features from second to last layer of CNN\")\n",
    "            feature_extractor = K.function([mnist_cnn.layers[0].input, K.learning_phase()],\n",
    "                                           [mnist_cnn.layers[-2].output])\n",
    "            features = feature_extractor([images, 0])[0]\n",
    "    \n",
    "    gp_mu, gp_var = gp.predict_y(features)\n",
    "\n",
    "    \n",
    "    decisions = []\n",
    "    decision_probs = []\n",
    "    decision_vars = []\n",
    "    for (mu, var, cnn_probs) in zip(gp_mu, gp_var, cnn_probs_batch):\n",
    "        cnn_class = np.argmax(cnn_probs)\n",
    "        gp_class = np.argmax(mu)\n",
    "        \n",
    "        gp_pred_prob = mu[gp_class]\n",
    "        gp_pred_var = var[gp_class]\n",
    "        \n",
    "        cnn_pred_prob = cnn_probs[cnn_class]\n",
    "        \n",
    "        # both classes agree\n",
    "        if gp_class == cnn_class:\n",
    "            # we may have to accept the wrong decision but can't do anything about it\n",
    "            #if verbose:\n",
    "            #    print(\"Models agree on predicted class\")\n",
    "            decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "            decision_probs.append(mu)\n",
    "            decision_vars.append(var)\n",
    "\n",
    "        else:\n",
    "            # disagreement! This is additional information\n",
    "            # From prior experiments we suspect that NN is more likely to be correct [non-adverserial examples tested]\n",
    "            # So, if we take the CNN prediction and check if it's the same as the _second_ highest GP prediction\n",
    "            # try using that?\n",
    "\n",
    "            # Revised:\n",
    "            #  Take the CNN prediction IF it's probability is within 1 stddev of the corresponding GP class probability\n",
    "\n",
    "            # core idea: if CNN is _too_ sure then we revert to GP prediction -- might be adverserial...?\n",
    "\n",
    "            gp_prob_for_cnn_pred = mu[cnn_class]\n",
    "            gp_stddev_for_cnn_pred = np.sqrt(var[cnn_class])\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Models disagree on predicted class\")\n",
    "\n",
    "            if cnn_pred_prob < (gp_prob_for_cnn_pred + accept_cnn_stddev*gp_stddev_for_cnn_pred):\n",
    "                if verbose:\n",
    "                    print(\"  Taking CNN prediction, probability is within\", accept_cnn_stddev, \"stddev of GP probability\")\n",
    "                decisions.append([1, cnn_class, cnn_pred_prob, -1])\n",
    "                decision_probs.append(cnn_probs)\n",
    "                decision_vars.append([-1 for x in range(mu.shape[-1])])\n",
    "\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"  Taking GP prediction\")\n",
    "                decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "                decision_probs.append(mu)\n",
    "                decision_vars.append(var)\n",
    "    return (np.array(decisions), np.array(decision_probs), np.array(decision_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Combined incorrect:  89\n"
     ]
    }
   ],
   "source": [
    "# combined_pred, combined_mus, combined_vars = combined_predict(cnn_path=\"../models/mnist_cnn.h5\", gp=gp_model, images=mnist_test_full_reshape, accept_cnn_stddev=1.0)\n",
    "combined_pred, combined_mus, combined_vars = combined_predict_efficient(cnn_test_probs, mu, var, accept_cnn_stddev=1.0)\n",
    "combined_pred_classes = combined_pred[:, 1]\n",
    "combined_incorrect = combined_pred_classes != correct_classes\n",
    "print(\"Num Combined incorrect: \", np.count_nonzero(combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have all 3 models available now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_keras import cnn_model\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "\n",
    "\n",
    "#adv_predictions = None\n",
    "#perturbed = None\n",
    "def perturb_images(model_path, data, eps=0.2, ):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        with tf.Session().as_default() as sess:\n",
    "            K.set_learning_phase(0) #set learning phase\n",
    "\n",
    "            #make a fresh copy to not modify other graph\n",
    "            model = keras.models.load_model(model_path)\n",
    "\n",
    "            x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "            y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "            # Initialize the Fast Gradient Sign Method (FGSM) attack object and graph\n",
    "            wrap = KerasModelWrapper(model)\n",
    "            fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "            fgsm_params = {'eps': eps,\n",
    "                           'clip_min': 0.,\n",
    "                           'clip_max': 1.}\n",
    "            adv_x = fgsm.generate(x, **fgsm_params)\n",
    "            # Consider the attack to be constant\n",
    "            adv_x = tf.stop_gradient(adv_x)\n",
    "            preds_adv = model(adv_x)\n",
    "\n",
    "            adv_predictions = sess.run(preds_adv, {x: data})\n",
    "            perturbed = sess.run(adv_x, {x: data})\n",
    "            \n",
    "            return (adv_predictions, perturbed)\n",
    "        \n",
    "adv_predictions, perturbed = perturb_images(mnist_cnn_path, mnist_test_full_reshape, eps=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist(x, ys, one_hot_encode=-1):\n",
    "    xs = x.copy()\n",
    "    img_rows, img_cols = 28, 28    \n",
    "    # reshape to inputs to correct shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        xs = xs.reshape(xs.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        xs = xs.reshape(xs.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    xs = xs.astype('float32')\n",
    "    xs /= 255\n",
    "    \n",
    "    if one_hot_encode != -1:\n",
    "        ys = keras.utils.to_categorical(ys, one_hot_encode) # one_hot_encode is the number of classes\n",
    "    \n",
    "    return (xs, ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(model_path, images):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default() as sess:\n",
    "            K.set_session(sess)\n",
    "            K.set_learning_phase(0) #set learning phase\n",
    "\n",
    "            #make a fresh copy to not modify other graph\n",
    "            model = keras.models.load_model(model_path)\n",
    "            feature_extractor = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                           [model.layers[6].output])\n",
    "            #pert, ys = preprocess_mnist(perturbed, ys_test_full)\n",
    "            #print(pert.shape)\n",
    "            return feature_extractor([images])[0]\n",
    "\n",
    "adv_fsgm_features = extract_features(mnist_cnn_path, perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP fsgm adversarial incorrect:  3475\n"
     ]
    }
   ],
   "source": [
    "# with gpflow.session_manager.get_session().as_default():\n",
    "(adv_mu, adv_var) = gp_model.predict_y(adv_fsgm_features)\n",
    "adv_gp_preds = np.argmax(adv_mu, axis=1)\n",
    "print(\"GP fsgm adversarial incorrect: \", np.count_nonzero(correct_classes != adv_gp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Combined incorrect:  3765\n"
     ]
    }
   ],
   "source": [
    "adv_combined_pred, adv_combined_mus, adv_combined_vars = combined_predict(cnn_path=\"../models/mnist_cnn.h5\", gp=gp_model, images=perturbed, accept_cnn_stddev=1.5)\n",
    "adv_combined_pred_classes = adv_combined_pred[:, 1]\n",
    "adv_combined_incorrect = adv_combined_pred_classes != correct_classes\n",
    "print(\"Num Combined incorrect: \", np.count_nonzero(adv_combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epsilons = np.arange(0, 0.4, 0.025)\n",
    "# stddev_accepts = np.arange(0.0, 2.5, 0.25)\n",
    "\n",
    "# for eps in epsilons:\n",
    "#     adv_cnn_predictions, perturbed = perturb_images(mnist_cnn_path, mnist_test_full_reshape, eps=eps)\n",
    "#     adv_cnn_classes = np.argmax(adv_cnn_predictions, axis=1)\n",
    "    \n",
    "#     #print(\"Incorrect: \", np.count_nonzero(correct_classes != adv_cnn_classes))\n",
    "\n",
    "#     adv_fsgm_features = extract_features(mnist_cnn_path)\n",
    "#     (adv_mu, adv_var) = gp_model.predict_y(adv_fsgm_features)\n",
    "#     adv_gp_preds = np.argmax(adv_mu, axis=1)\n",
    "        \n",
    "#     adv_cnn_correct = adv_cnn_classes == correct_classes\n",
    "#     adv_gp_correct = adv_gp_preds == correct_classes\n",
    "    \n",
    "#     n = len(correct_classes)\n",
    "    \n",
    "#     print(\"Epsilon =\", eps)\n",
    "#     print(\"  CNN accuracy: \", np.count_nonzero(adv_cnn_correct) / n)\n",
    "#     print(\"  GP accuracy: \", np.count_nonzero(adv_gp_correct) / n)\n",
    "    \n",
    "#     for stddev_accept in stddev_accepts:\n",
    "#         adv_combined_pred, adv_combined_mus, adv_combined_vars = combined_predict_efficient(adv_cnn_predictions, adv_mu, adv_var, accept_cnn_stddev=stddev_accept)\n",
    "\n",
    "#         adv_combined_pred_classes = adv_combined_pred[:, 1]\n",
    "#         adv_combined_correct = adv_combined_pred_classes == correct_classes\n",
    "\n",
    "#         print(\"  Combined accuracy (accept = \", stddev_accept, \"): \", np.count_nonzero(adv_combined_correct) / n)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM for comparison as well\n",
    "from sklearn import svm\n",
    "mnist_svm = svm.SVC(decision_function_shape='ovo', probability=True)\n",
    "ys = np.argmax(ys_train_full, axis=1) # no need for 1-hot encoding\n",
    "mnist_svm.fit(xs_train_full, ys) \n",
    "\n",
    "#pred = clf.predict(xs_test_full)\n",
    "#print(pred)\n",
    "#print(\"SVM correct classificaitons: \",  np.count_nonzero(pred != correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.0\n",
      "  CNN accuracy:  0.9911\n",
      "  GP accuracy:  0.9905\n",
      "  SVM accuracy:  0.9937\n",
      "  Combined accuracy (accept =  0.0 ):  0.9905\n",
      "  Combined accuracy (accept =  0.25 ):  0.9906\n",
      "  Combined accuracy (accept =  0.5 ):  0.9906\n",
      "  Combined accuracy (accept =  0.75 ):  0.991\n",
      "  Combined accuracy (accept =  1.0 ):  0.9911\n",
      "  Combined accuracy (accept =  1.25 ):  0.991\n",
      "  Combined accuracy (accept =  1.5 ):  0.9911\n",
      "  Combined accuracy (accept =  1.75 ):  0.9911\n",
      "  Combined accuracy (accept =  2.0 ):  0.9911\n",
      "  Combined accuracy (accept =  2.25 ):  0.9911\n",
      "Epsilon = 0.025\n",
      "  CNN accuracy:  0.9888\n",
      "  GP accuracy:  0.9863\n",
      "  SVM accuracy:  0.9905\n",
      "  Combined accuracy (accept =  0.0 ):  0.9863\n",
      "  Combined accuracy (accept =  0.25 ):  0.986\n",
      "  Combined accuracy (accept =  0.5 ):  0.9864\n",
      "  Combined accuracy (accept =  0.75 ):  0.9865\n",
      "  Combined accuracy (accept =  1.0 ):  0.9882\n",
      "  Combined accuracy (accept =  1.25 ):  0.9886\n",
      "  Combined accuracy (accept =  1.5 ):  0.9889\n",
      "  Combined accuracy (accept =  1.75 ):  0.9889\n",
      "  Combined accuracy (accept =  2.0 ):  0.9888\n",
      "  Combined accuracy (accept =  2.25 ):  0.9888\n",
      "Epsilon = 0.05\n",
      "  CNN accuracy:  0.9749\n",
      "  GP accuracy:  0.9766\n",
      "  SVM accuracy:  0.9787\n",
      "  Combined accuracy (accept =  0.0 ):  0.9765\n",
      "  Combined accuracy (accept =  0.25 ):  0.9762\n",
      "  Combined accuracy (accept =  0.5 ):  0.9757\n",
      "  Combined accuracy (accept =  0.75 ):  0.9753\n",
      "  Combined accuracy (accept =  1.0 ):  0.9746\n",
      "  Combined accuracy (accept =  1.25 ):  0.9749\n",
      "  Combined accuracy (accept =  1.5 ):  0.975\n",
      "  Combined accuracy (accept =  1.75 ):  0.975\n",
      "  Combined accuracy (accept =  2.0 ):  0.975\n",
      "  Combined accuracy (accept =  2.25 ):  0.975\n",
      "Epsilon = 0.075\n",
      "  CNN accuracy:  0.9549\n",
      "  GP accuracy:  0.9539\n",
      "  SVM accuracy:  0.9593\n",
      "  Combined accuracy (accept =  0.0 ):  0.9539\n",
      "  Combined accuracy (accept =  0.25 ):  0.9541\n",
      "  Combined accuracy (accept =  0.5 ):  0.9542\n",
      "  Combined accuracy (accept =  0.75 ):  0.9547\n",
      "  Combined accuracy (accept =  1.0 ):  0.9553\n",
      "  Combined accuracy (accept =  1.25 ):  0.9551\n",
      "  Combined accuracy (accept =  1.5 ):  0.9553\n",
      "  Combined accuracy (accept =  1.75 ):  0.9552\n",
      "  Combined accuracy (accept =  2.0 ):  0.9551\n",
      "  Combined accuracy (accept =  2.25 ):  0.9551\n",
      "Epsilon = 0.1\n",
      "  CNN accuracy:  0.9191\n",
      "  GP accuracy:  0.9185\n",
      "  SVM accuracy:  0.9219\n",
      "  Combined accuracy (accept =  0.0 ):  0.9186\n",
      "  Combined accuracy (accept =  0.25 ):  0.9188\n",
      "  Combined accuracy (accept =  0.5 ):  0.9187\n",
      "  Combined accuracy (accept =  0.75 ):  0.9188\n",
      "  Combined accuracy (accept =  1.0 ):  0.9191\n",
      "  Combined accuracy (accept =  1.25 ):  0.9189\n",
      "  Combined accuracy (accept =  1.5 ):  0.9191\n",
      "  Combined accuracy (accept =  1.75 ):  0.9192\n",
      "  Combined accuracy (accept =  2.0 ):  0.9192\n",
      "  Combined accuracy (accept =  2.25 ):  0.9191\n",
      "Epsilon = 0.125\n",
      "  CNN accuracy:  0.8682\n",
      "  GP accuracy:  0.8709\n",
      "  SVM accuracy:  0.8718\n",
      "  Combined accuracy (accept =  0.0 ):  0.8709\n",
      "  Combined accuracy (accept =  0.25 ):  0.8707\n",
      "  Combined accuracy (accept =  0.5 ):  0.8719\n",
      "  Combined accuracy (accept =  0.75 ):  0.8699\n",
      "  Combined accuracy (accept =  1.0 ):  0.8692\n",
      "  Combined accuracy (accept =  1.25 ):  0.8691\n",
      "  Combined accuracy (accept =  1.5 ):  0.8683\n",
      "  Combined accuracy (accept =  1.75 ):  0.8686\n",
      "  Combined accuracy (accept =  2.0 ):  0.8679\n",
      "  Combined accuracy (accept =  2.25 ):  0.8679\n",
      "Epsilon = 0.15\n",
      "  CNN accuracy:  0.8002\n",
      "  GP accuracy:  0.8105\n",
      "  SVM accuracy:  0.8059\n",
      "  Combined accuracy (accept =  0.0 ):  0.8105\n",
      "  Combined accuracy (accept =  0.25 ):  0.8091\n",
      "  Combined accuracy (accept =  0.5 ):  0.8074\n",
      "  Combined accuracy (accept =  0.75 ):  0.8073\n",
      "  Combined accuracy (accept =  1.0 ):  0.8044\n",
      "  Combined accuracy (accept =  1.25 ):  0.8014\n",
      "  Combined accuracy (accept =  1.5 ):  0.8012\n",
      "  Combined accuracy (accept =  1.75 ):  0.8002\n",
      "  Combined accuracy (accept =  2.0 ):  0.8005\n",
      "  Combined accuracy (accept =  2.25 ):  0.8002\n",
      "Epsilon = 0.175\n",
      "  CNN accuracy:  0.7167\n",
      "  GP accuracy:  0.7358\n",
      "  SVM accuracy:  0.7193\n",
      "  Combined accuracy (accept =  0.0 ):  0.7357\n",
      "  Combined accuracy (accept =  0.25 ):  0.7355\n",
      "  Combined accuracy (accept =  0.5 ):  0.732\n",
      "  Combined accuracy (accept =  0.75 ):  0.7283\n",
      "  Combined accuracy (accept =  1.0 ):  0.7258\n",
      "  Combined accuracy (accept =  1.25 ):  0.7188\n",
      "  Combined accuracy (accept =  1.5 ):  0.7177\n",
      "  Combined accuracy (accept =  1.75 ):  0.7169\n",
      "  Combined accuracy (accept =  2.0 ):  0.7164\n",
      "  Combined accuracy (accept =  2.25 ):  0.7171\n",
      "Epsilon = 0.2\n",
      "  CNN accuracy:  0.6219\n",
      "  GP accuracy:  0.6525\n",
      "  SVM accuracy:  0.6243\n",
      "  Combined accuracy (accept =  0.0 ):  0.6525\n",
      "  Combined accuracy (accept =  0.25 ):  0.6508\n",
      "  Combined accuracy (accept =  0.5 ):  0.6466\n",
      "  Combined accuracy (accept =  0.75 ):  0.6421\n",
      "  Combined accuracy (accept =  1.0 ):  0.6354\n",
      "  Combined accuracy (accept =  1.25 ):  0.6275\n",
      "  Combined accuracy (accept =  1.5 ):  0.6235\n",
      "  Combined accuracy (accept =  1.75 ):  0.6226\n",
      "  Combined accuracy (accept =  2.0 ):  0.6229\n",
      "  Combined accuracy (accept =  2.25 ):  0.6229\n",
      "Epsilon = 0.225\n",
      "  CNN accuracy:  0.5226\n",
      "  GP accuracy:  0.5596\n",
      "  SVM accuracy:  0.5224\n",
      "  Combined accuracy (accept =  0.0 ):  0.5602\n",
      "  Combined accuracy (accept =  0.25 ):  0.5606\n",
      "  Combined accuracy (accept =  0.5 ):  0.5566\n",
      "  Combined accuracy (accept =  0.75 ):  0.5485\n",
      "  Combined accuracy (accept =  1.0 ):  0.5375\n",
      "  Combined accuracy (accept =  1.25 ):  0.5297\n",
      "  Combined accuracy (accept =  1.5 ):  0.5261\n",
      "  Combined accuracy (accept =  1.75 ):  0.5254\n",
      "  Combined accuracy (accept =  2.0 ):  0.5249\n",
      "  Combined accuracy (accept =  2.25 ):  0.5244\n",
      "Epsilon = 0.25\n",
      "  CNN accuracy:  0.4178\n",
      "  GP accuracy:  0.4729\n",
      "  SVM accuracy:  0.4175\n",
      "  Combined accuracy (accept =  0.0 ):  0.4733\n",
      "  Combined accuracy (accept =  0.25 ):  0.4685\n",
      "  Combined accuracy (accept =  0.5 ):  0.4604\n",
      "  Combined accuracy (accept =  0.75 ):  0.4432\n",
      "  Combined accuracy (accept =  1.0 ):  0.429\n",
      "  Combined accuracy (accept =  1.25 ):  0.4213\n",
      "  Combined accuracy (accept =  1.5 ):  0.4201\n",
      "  Combined accuracy (accept =  1.75 ):  0.4207\n",
      "  Combined accuracy (accept =  2.0 ):  0.4209\n",
      "  Combined accuracy (accept =  2.25 ):  0.4208\n",
      "Epsilon = 0.275\n",
      "  CNN accuracy:  0.3157\n",
      "  GP accuracy:  0.3864\n",
      "  SVM accuracy:  0.3146\n",
      "  Combined accuracy (accept =  0.0 ):  0.3852\n",
      "  Combined accuracy (accept =  0.25 ):  0.3823\n",
      "  Combined accuracy (accept =  0.5 ):  0.368\n",
      "  Combined accuracy (accept =  0.75 ):  0.3407\n",
      "  Combined accuracy (accept =  1.0 ):  0.3276\n",
      "  Combined accuracy (accept =  1.25 ):  0.3212\n",
      "  Combined accuracy (accept =  1.5 ):  0.3208\n",
      "  Combined accuracy (accept =  1.75 ):  0.3205\n",
      "  Combined accuracy (accept =  2.0 ):  0.3214\n",
      "  Combined accuracy (accept =  2.25 ):  0.322\n",
      "Epsilon = 0.3\n",
      "  CNN accuracy:  0.2342\n",
      "  GP accuracy:  0.3164\n",
      "  SVM accuracy:  0.2315\n",
      "  Combined accuracy (accept =  0.0 ):  0.3159\n",
      "  Combined accuracy (accept =  0.25 ):  0.3138\n",
      "  Combined accuracy (accept =  0.5 ):  0.2902\n",
      "  Combined accuracy (accept =  0.75 ):  0.2577\n",
      "  Combined accuracy (accept =  1.0 ):  0.2428\n",
      "  Combined accuracy (accept =  1.25 ):  0.2388\n",
      "  Combined accuracy (accept =  1.5 ):  0.2384\n",
      "  Combined accuracy (accept =  1.75 ):  0.2406\n",
      "  Combined accuracy (accept =  2.0 ):  0.2415\n",
      "  Combined accuracy (accept =  2.25 ):  0.2411\n",
      "Epsilon = 0.325\n",
      "  CNN accuracy:  0.1719\n",
      "  GP accuracy:  0.2606\n",
      "  SVM accuracy:  0.17\n",
      "  Combined accuracy (accept =  0.0 ):  0.2601\n",
      "  Combined accuracy (accept =  0.25 ):  0.2571\n",
      "  Combined accuracy (accept =  0.5 ):  0.2271\n",
      "  Combined accuracy (accept =  0.75 ):  0.1901\n",
      "  Combined accuracy (accept =  1.0 ):  0.1792\n",
      "  Combined accuracy (accept =  1.25 ):  0.1768\n",
      "  Combined accuracy (accept =  1.5 ):  0.1769\n",
      "  Combined accuracy (accept =  1.75 ):  0.1783\n",
      "  Combined accuracy (accept =  2.0 ):  0.1787\n",
      "  Combined accuracy (accept =  2.25 ):  0.1776\n",
      "Epsilon = 0.35\n",
      "  CNN accuracy:  0.1279\n",
      "  GP accuracy:  0.2182\n",
      "  SVM accuracy:  0.1265\n",
      "  Combined accuracy (accept =  0.0 ):  0.2174\n",
      "  Combined accuracy (accept =  0.25 ):  0.2152\n",
      "  Combined accuracy (accept =  0.5 ):  0.1804\n",
      "  Combined accuracy (accept =  0.75 ):  0.1431\n",
      "  Combined accuracy (accept =  1.0 ):  0.1343\n",
      "  Combined accuracy (accept =  1.25 ):  0.1324\n",
      "  Combined accuracy (accept =  1.5 ):  0.1318\n",
      "  Combined accuracy (accept =  1.75 ):  0.1331\n",
      "  Combined accuracy (accept =  2.0 ):  0.1342\n",
      "  Combined accuracy (accept =  2.25 ):  0.1336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.375\n",
      "  CNN accuracy:  0.1013\n",
      "  GP accuracy:  0.1874\n",
      "  SVM accuracy:  0.0993\n",
      "  Combined accuracy (accept =  0.0 ):  0.1869\n",
      "  Combined accuracy (accept =  0.25 ):  0.1856\n",
      "  Combined accuracy (accept =  0.5 ):  0.1495\n",
      "  Combined accuracy (accept =  0.75 ):  0.1127\n",
      "  Combined accuracy (accept =  1.0 ):  0.1052\n",
      "  Combined accuracy (accept =  1.25 ):  0.1024\n",
      "  Combined accuracy (accept =  1.5 ):  0.1034\n",
      "  Combined accuracy (accept =  1.75 ):  0.1048\n",
      "  Combined accuracy (accept =  2.0 ):  0.1054\n",
      "  Combined accuracy (accept =  2.25 ):  0.1049\n"
     ]
    }
   ],
   "source": [
    "epsilons = np.arange(0, 0.4, 0.025)\n",
    "stddev_accepts = np.arange(0.0, 2.5, 0.25)\n",
    "stddev_keep = [0.5, 1.0]\n",
    "\n",
    "n = len(correct_classes)\n",
    "\n",
    "def acc(correct):\n",
    "    return np.count_nonzero(correct) / n\n",
    "    \n",
    "accuracies = []\n",
    "for eps in epsilons:\n",
    "    adv_cnn_predictions, perturbed = perturb_images(mnist_cnn_path, mnist_test_full_reshape, eps=eps)\n",
    "    adv_cnn_classes = np.argmax(adv_cnn_predictions, axis=1)\n",
    "    \n",
    "    #print(\"Incorrect: \", np.count_nonzero(correct_classes != adv_cnn_classes))\n",
    "\n",
    "    adv_fsgm_features = extract_features(mnist_cnn_path, perturbed)\n",
    "    (adv_mu, adv_var) = gp_model.predict_y(adv_fsgm_features)\n",
    "    adv_gp_preds = np.argmax(adv_mu, axis=1)\n",
    "        \n",
    "    adv_cnn_correct = adv_cnn_classes == correct_classes\n",
    "    adv_gp_correct = adv_gp_preds == correct_classes\n",
    "    \n",
    "    adv_svm_preds = mnist_svm.predict(adv_fsgm_features)\n",
    "    adv_svm_correct = adv_svm_preds == correct_classes\n",
    "    \n",
    "    \n",
    "    print(\"Epsilon =\", eps)\n",
    "    print(\"  CNN accuracy: \", acc(adv_cnn_correct))\n",
    "    print(\"  GP accuracy: \", acc(adv_gp_correct))\n",
    "    print(\"  SVM accuracy: \", acc(adv_svm_correct))\n",
    "    \n",
    "    accuracies.append([acc(adv_cnn_correct), acc(adv_gp_correct), acc(adv_svm_correct)])\n",
    "    for stddev_accept in stddev_accepts:\n",
    "        adv_combined_pred, adv_combined_mus, adv_combined_vars = combined_predict_efficient(adv_cnn_predictions, adv_mu, adv_var, accept_cnn_stddev=stddev_accept)\n",
    "\n",
    "        adv_combined_pred_classes = adv_combined_pred[:, 1]\n",
    "        adv_combined_correct = adv_combined_pred_classes == correct_classes\n",
    "\n",
    "        print(\"  Combined accuracy (accept = \", stddev_accept, \"): \", acc(adv_combined_correct))\n",
    "        if stddev_accept in stddev_keep:\n",
    "            accuracies[-1].append(acc(adv_combined_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
