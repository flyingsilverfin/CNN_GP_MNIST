{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    " \n",
    "\n",
    "\n",
    "xs_train_full = np.genfromtxt(\"../data/mnist_train_features.csv\", delimiter=\",\")\n",
    "xs_test_full = np.genfromtxt(\"../data/mnist_test_features.csv\", delimiter=\",\")\n",
    "\n",
    "def get_mnist_classes():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return ((x_train, x_test), (y_train, y_test))\n",
    "\n",
    "((mnist_train_full, mnist_test_full), (ys_train_full, ys_test_full)) = get_mnist_classes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 128 features, predicting 10 classes\n"
     ]
    }
   ],
   "source": [
    "# fitting entirety of model on base MNIST data\n",
    "\n",
    "num_features = xs_train_full.shape[-1]\n",
    "num_classes = 10\n",
    "print(\"Using\", num_features, \"features, predicting\", num_classes, \"classes\")\n",
    "\n",
    "ys = np.argmax(ys_train_full, axis=1)\n",
    "\n",
    "gp_model = gpflow.models.SVGP(\n",
    "    xs_train_full, ys, kern=gpflow.kernels.Matern32(input_dim=num_features) + gpflow.kernels.White(input_dim=num_features, variance=0.1),\n",
    "    likelihood=gpflow.likelihoods.MultiClass(num_classes),\n",
    "    Z=xs_train_full[::20].copy(), \n",
    "    num_latent=num_classes, \n",
    "    whiten=True, \n",
    "    q_diag=True,\n",
    "    minibatch_size=8000)\n",
    "gp_model.kern.white.variance.trainable = False\n",
    "#gp_model.feature.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 6100.389939\n",
      "  Number of iterations: 18\n",
      "  Number of functions evaluations: 34\n"
     ]
    }
   ],
   "source": [
    "opt = gpflow.train.ScipyOptimizer()\n",
    "opt.minimize(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, var) = gp_model.predict_y(xs_test_full)\n",
    "gp_predicted_classes = np.argmax(mu, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_classes = np.argmax(ys_test_full, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GP incorrect:  92\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GP incorrect: \", np.count_nonzero(gp_predicted_classes != correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "\n",
    "mnist_test_full_reshape = mnist_test_full_reshape.astype('float32')\n",
    "mnist_test_full_reshape /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CNN incorrect: 89\n"
     ]
    }
   ],
   "source": [
    "K.get_session().close() # just to be sure\n",
    "\n",
    "# Keras approach!\n",
    "\n",
    "# release graph resources when done otherwise inconsistent results\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session().as_default() as sess:\n",
    "        K.set_session(sess)\n",
    "        mnist_cnn = keras.models.load_model('../models/mnist_cnn.h5')\n",
    "        cnn_test_probs = mnist_cnn.predict_on_batch(mnist_test_full_reshape)\n",
    "        cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\n",
    "        print(\"Num CNN incorrect:\", np.count_nonzero(cnn_predicted_classes != correct_classes))\n",
    "        K.get_session().close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CNN incorrect: 89\n"
     ]
    }
   ],
   "source": [
    "# TF approach!\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        K.set_learning_phase(0) #set learning phase to test!\n",
    "        # get the full CNN\n",
    "        mnist_cnn = keras.models.load_model('../models/mnist_cnn.h5')\n",
    "        \n",
    "        x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "        cnn_preds_placeholder = mnist_cnn(x)\n",
    "\n",
    "        cnn_test_probs = cnn_preds_placeholder.eval(feed_dict={x: mnist_test_full_reshape})\n",
    "        \n",
    "        cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\n",
    "        print(\"Num CNN incorrect:\", np.count_nonzero(cnn_predicted_classes != correct_classes))\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "\n",
    "\"\"\"\n",
    "params:\n",
    "    cnn_path: trained mnist CNN file path\n",
    "    gp: trained gaussian process for multiclass classification\n",
    "    verbose: printing on/off \n",
    "    accept_cnn_stddev: if CNN predicted class has higher prob than GP's, this is number of stddevs the CNN prediction needs to be within from the GP prediction to acccept it\n",
    "        ie. higher = more likely to revert to CNN!\n",
    "\"\"\"\n",
    "def combined_predict(cnn_path, gp, images, verbose=False, accept_cnn_stddev=1):\n",
    "    # so my CNN can only predict on batches of 4 or greater...\n",
    "    if images.shape[0] < 4:\n",
    "        print(\"Can only predict with >= 4 images at a time\")\n",
    "        return\n",
    "    batch = images\n",
    "    \n",
    "    cnn_probs_batch = None\n",
    "    features = None\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default():\n",
    "            mnist_cnn = keras.models.load_model(cnn_path)\n",
    "            cnn_probs_batch = mnist_cnn.predict_on_batch(mnist_test_full_reshape)\n",
    "    \n",
    "            # need to get output of second to last layer in CNN to feed into GP\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Extracting features from second to last layer of CNN\")\n",
    "            feature_extractor = K.function([mnist_cnn.layers[0].input, K.learning_phase()],\n",
    "                                           [mnist_cnn.layers[-2].output])\n",
    "            features = feature_extractor([images, 0])[0]\n",
    "    \n",
    "    gp_mu, gp_var = gp.predict_y(features)\n",
    "\n",
    "    \n",
    "    decisions = []\n",
    "    decision_probs = []\n",
    "    decision_vars = []\n",
    "    for (mu, var, cnn_probs) in zip(gp_mu, gp_var, cnn_probs_batch):\n",
    "        cnn_class = np.argmax(cnn_probs)\n",
    "        gp_class = np.argmax(mu)\n",
    "        \n",
    "        gp_pred_prob = mu[gp_class]\n",
    "        gp_pred_var = var[gp_class]\n",
    "        \n",
    "        cnn_pred_prob = cnn_probs[cnn_class]\n",
    "        \n",
    "        # both classes agree\n",
    "        if gp_class == cnn_class:\n",
    "            # we may have to accept the wrong decision but can't do anything about it\n",
    "            #if verbose:\n",
    "            #    print(\"Models agree on predicted class\")\n",
    "            decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "            decision_probs.append(mu)\n",
    "            decision_vars.append(var)\n",
    "\n",
    "        else:\n",
    "            # disagreement! This is additional information\n",
    "            # From prior experiments we suspect that NN is more likely to be correct [non-adverserial examples tested]\n",
    "            # So, if we take the CNN prediction and check if it's the same as the _second_ highest GP prediction\n",
    "            # try using that?\n",
    "\n",
    "            # Revised:\n",
    "            #  Take the CNN prediction IF it's probability is within 1 stddev of the corresponding GP class probability\n",
    "\n",
    "            # core idea: if CNN is _too_ sure then we revert to GP prediction -- might be adverserial...?\n",
    "\n",
    "            gp_prob_for_cnn_pred = mu[cnn_class]\n",
    "            gp_stddev_for_cnn_pred = np.sqrt(var[cnn_class])\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Models disagree on predicted class\")\n",
    "\n",
    "            if cnn_pred_prob < (gp_prob_for_cnn_pred + accept_cnn_stddev*gp_stddev_for_cnn_pred):\n",
    "                if verbose:\n",
    "                    print(\"  Taking CNN prediction, probability is within\", accept_cnn_stddev, \"stddev of GP probability\")\n",
    "                decisions.append([1, cnn_class, cnn_pred_prob, -1])\n",
    "                decision_probs.append(cnn_probs)\n",
    "                decision_vars.append([-1 for x in range(mu.shape[-1])])\n",
    "\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"  Taking GP prediction\")\n",
    "                decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "                decision_probs.append(mu)\n",
    "                decision_vars.append(var)\n",
    "    return (np.array(decisions), np.array(decision_probs), np.array(decision_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Combined incorrect:  90\n"
     ]
    }
   ],
   "source": [
    "combined_pred, combined_mus, combined_vars = combined_predict(cnn_path=\"../models/mnist_cnn.h5\", gp=gp_model, images=mnist_test_full_reshape, accept_cnn_stddev=1.0)\n",
    "combined_pred_classes = combined_pred[:, 1]\n",
    "combined_incorrect = combined_pred_classes != correct_classes\n",
    "print(\"Num Combined incorrect: \", np.count_nonzero(combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have all 3 models available now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_keras import cnn_model\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "\n",
    "\n",
    "adv_predictions = None\n",
    "perturbed = None\n",
    "with tf.Graph().as_default() as graph:\n",
    "    with tf.Session().as_default() as sess:\n",
    "        K.set_learning_phase(0) #set learning phase\n",
    "\n",
    "        #make a fresh copy to not modify other graph\n",
    "        model = keras.models.load_model('../models/mnist_cnn.h5')\n",
    "            \n",
    "        x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "        y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "        # Initialize the Fast Gradient Sign Method (FGSM) attack object and graph\n",
    "        wrap = KerasModelWrapper(model)\n",
    "        fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "        fgsm_params = {'eps': 0.10,\n",
    "                       'clip_min': 0.,\n",
    "                       'clip_max': 1.}\n",
    "        adv_x = fgsm.generate(x, **fgsm_params)\n",
    "        # Consider the attack to be constant\n",
    "        adv_x = tf.stop_gradient(adv_x)\n",
    "        preds_adv = model(adv_x)\n",
    "\n",
    "        adv_predictions = sess.run(preds_adv, {x: mnist_test_full_reshape})\n",
    "        perturbed = sess.run(adv_x, {x: mnist_test_full_reshape})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "Incorrect:  809\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niwRKyS8SKCW/SKCU/CKB+n9Q4YHrnoefUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40afe07cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(perturbed.shape)\n",
    "plt.imshow(perturbed[3].reshape((28,28)), cmap=plt.get_cmap('gray'))\n",
    "print(\"Incorrect: \", np.count_nonzero(correct_classes != np.argmax(adv_predictions, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist(xs, ys, one_hot_encode=-1):\n",
    "    img_rows, img_cols = 28, 28    \n",
    "    # reshape to inputs to correct shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        xs = xs.reshape(xs.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        xs = xs.reshape(xs.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    xs = xs.astype('float32')\n",
    "    xs /= 255\n",
    "    \n",
    "    if one_hot_encode != -1:\n",
    "        ys = keras.utils.to_categorical(ys, one_hot_encode) # one_hot_encode is the number of classes\n",
    "    \n",
    "    return (xs, ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_fsgm_features = None\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session().as_default() as sess:\n",
    "        K.set_session(sess)\n",
    "        K.set_learning_phase(0) #set learning phase\n",
    "\n",
    "        #make a fresh copy to not modify other graph\n",
    "        model = keras.models.load_model('../models/mnist_cnn.h5')\n",
    "        feature_extractor = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                       [model.layers[6].output])\n",
    "        pert, ys = preprocess_mnist(perturbed, ys_test_full)\n",
    "        adv_fsgm_features = feature_extractor([pert])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_fsgm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP fsgm adversarial incorrect:  8865\n"
     ]
    }
   ],
   "source": [
    "with gpflow.session_manager.get_session().as_default():\n",
    "    (adv_mu, adv_var) = gp_model.predict_y(adv_fsgm_features)\n",
    "    adv_gp_preds = np.argmax(adv_mu, axis=1)\n",
    "    print(\"GP fsgm adversarial incorrect: \", np.count_nonzero(correct_classes != adv_gp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.client.session.Session"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Combined incorrect:  802\n"
     ]
    }
   ],
   "source": [
    "adv_combined_pred, adv_combined_mus, adv_combined_vars = combined_predict(cnn_path=\"../models/mnist_cnn.h5\", gp=gp_model, images=perturbed, accept_cnn_stddev=0.5)\n",
    "adv_combined_pred_classes = adv_combined_pred[:, 1]\n",
    "adv_combined_incorrect = adv_combined_pred_classes != correct_classes\n",
    "print(\"Num Combined incorrect: \", np.count_nonzero(adv_combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
