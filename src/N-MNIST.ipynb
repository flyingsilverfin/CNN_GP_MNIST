{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    " \n",
    "\n",
    "xs_train_full = np.genfromtxt(\"../data/mnist_train_features.csv\", delimiter=\",\")\n",
    "xs_test_full = np.genfromtxt(\"../data/mnist_test_features.csv\", delimiter=\",\")\n",
    "\n",
    "def get_mnist_classes():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return ((x_train, x_test), (y_train, y_test))\n",
    "\n",
    "((mnist_train_full, mnist_test_full), (ys_train_full, ys_test_full)) = get_mnist_classes()\n",
    "correct_classes = np.argmax(ys_test_full, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 128 features, predicting 10 classes\n"
     ]
    }
   ],
   "source": [
    "# fitting entirety of model on base MNIST data\n",
    "\n",
    "num_features = xs_train_full.shape[-1]\n",
    "num_classes = 10\n",
    "print(\"Using\", num_features, \"features, predicting\", num_classes, \"classes\")\n",
    "\n",
    "ys = np.argmax(ys_train_full, axis=1)\n",
    "\n",
    "# Matern12, white var=0.1, ::25, minibatch=8k, kern.white.var.train = False, feature.trainable=True\n",
    "\n",
    "# Matern 32, White var=0.1, ::20, minibatch = 8000, kern.white.variance.trainable = True, feature.trainable = False\n",
    "#   Note: this has interesting properties for AWGN results: hybrid model outperforms both. But in other cases not...\n",
    "# Best:\n",
    "# ! Matern 32, White var=0.1, ::20, minibatch = 8000, kern.white.variance.trainable = False(feature.trainable = True)\n",
    "\n",
    "# Matern52, White var=0.1, ::25, minibatch=8000, white trainable=False\n",
    "\n",
    "# Linear, white var=0.1, ::20, minibatch=8k, white trainable =False\n",
    "gp_model = gpflow.models.SVGP(\n",
    "    xs_train_full, ys, kern=gpflow.kernels.Linear(input_dim=num_features) + gpflow.kernels.White(input_dim=num_features, variance=0.1),\n",
    "    likelihood=gpflow.likelihoods.MultiClass(num_classes),\n",
    "    Z=xs_train_full[::20].copy(), \n",
    "    num_latent=num_classes, \n",
    "    whiten=True, \n",
    "    q_diag=True,\n",
    "    minibatch_size=8000)\n",
    "gp_model.kern.white.variance.trainable = False\n",
    "#gp_model.feature.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 4515.149993\n",
      "  Number of iterations: 11\n",
      "  Number of functions evaluations: 20\n"
     ]
    }
   ],
   "source": [
    "opt = gpflow.train.ScipyOptimizer()\n",
    "opt.minimize(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GP incorrect:  102\n"
     ]
    }
   ],
   "source": [
    "(mu, var) = gp_model.predict_y(xs_test_full)\n",
    "gp_predicted_classes = np.argmax(mu, axis=1)\n",
    "print(\"Num GP incorrect: \", np.count_nonzero(gp_predicted_classes != correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVGP/kern/white/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVGP/kern/linear/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.047442193194886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVGP/q_mu</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>(none)</td>\n",
       "      <td>True</td>\n",
       "      <td>(3000, 10)</td>\n",
       "      <td>True</td>\n",
       "      <td>[[-2.3135743513, -2.81427481817, -4.4071718795...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVGP/feature/Z</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>(none)</td>\n",
       "      <td>True</td>\n",
       "      <td>(3000, 128)</td>\n",
       "      <td>True</td>\n",
       "      <td>[[3.88213660939, 0.18223541999, 2.85461201275,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVGP/q_sqrt</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>(3000, 10)</td>\n",
       "      <td>True</td>\n",
       "      <td>[[0.343735744257, 0.3221284087, 0.268484167645...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               class prior transform  trainable        shape  \\\n",
       "SVGP/kern/white/variance   Parameter  None       +ve      False           ()   \n",
       "SVGP/kern/linear/variance  Parameter  None       +ve       True           ()   \n",
       "SVGP/q_mu                  Parameter  None    (none)       True   (3000, 10)   \n",
       "SVGP/feature/Z             Parameter  None    (none)       True  (3000, 128)   \n",
       "SVGP/q_sqrt                Parameter  None       +ve       True   (3000, 10)   \n",
       "\n",
       "                           fixed_shape  \\\n",
       "SVGP/kern/white/variance          True   \n",
       "SVGP/kern/linear/variance         True   \n",
       "SVGP/q_mu                         True   \n",
       "SVGP/feature/Z                    True   \n",
       "SVGP/q_sqrt                       True   \n",
       "\n",
       "                                                                       value  \n",
       "SVGP/kern/white/variance                                                 0.1  \n",
       "SVGP/kern/linear/variance                                  1.047442193194886  \n",
       "SVGP/q_mu                  [[-2.3135743513, -2.81427481817, -4.4071718795...  \n",
       "SVGP/feature/Z             [[3.88213660939, 0.18223541999, 2.85461201275,...  \n",
       "SVGP/q_sqrt                [[0.343735744257, 0.3221284087, 0.268484167645...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_model.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full CNN\n",
    "mnist_cnn = keras.models.load_model('../models/mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    mnist_test_full_reshape = mnist_test_full.reshape(xs_test_full.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "\n",
    "mnist_test_full_reshape = mnist_test_full_reshape.astype('float32')\n",
    "mnist_test_full_reshape /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CNN incorrect: 89\n"
     ]
    }
   ],
   "source": [
    "cnn_test_probs = mnist_cnn.predict_on_batch(mnist_test_full_reshape)\n",
    "cnn_predicted_classes = np.argmax(cnn_test_probs, axis=1)\n",
    "print(\"Num CNN incorrect:\", np.count_nonzero(cnn_predicted_classes != correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9911\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(cnn_predicted_classes != correct_classes)/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "params:\n",
    "    cnn_probs\n",
    "    gp_probs,\n",
    "    gp_vars,\n",
    "    verbose,\n",
    "    accept_cnn_stddev\n",
    "\"\"\"\n",
    "\n",
    "def combined_predict_efficient(cnn_probs_all, gp_mu, gp_var, verbose=False, accept_cnn_stddev = 1.0):\n",
    "    assert (cnn_probs_all.shape[0] == gp_mu.shape[0] == gp_var.shape[0])\n",
    "    decisions = []\n",
    "    decision_probs = []\n",
    "    decision_vars = []\n",
    "    for (mu, var, cnn_probs) in zip(gp_mu, gp_var, cnn_probs_all):\n",
    "        cnn_class = np.argmax(cnn_probs)\n",
    "        gp_class = np.argmax(mu)\n",
    "        \n",
    "        gp_pred_prob = mu[gp_class]\n",
    "        gp_pred_var = var[gp_class]\n",
    "        \n",
    "        cnn_pred_prob = cnn_probs[cnn_class]\n",
    "        \n",
    "        # both classes agree\n",
    "        if gp_class == cnn_class:\n",
    "            # we may have to accept the wrong decision but can't do anything about it\n",
    "            #if verbose:\n",
    "            #    print(\"Models agree on predicted class\")\n",
    "            decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "            decision_probs.append(mu)\n",
    "            decision_vars.append(var)\n",
    "        else:\n",
    "            # disagreement! This is additional information\n",
    "            # From prior experiments we suspect that NN is more likely to be correct [non-adverserial examples tested]\n",
    "            # So, if we take the CNN prediction and check if it's the same as the _second_ highest GP prediction\n",
    "            # try using that?\n",
    "\n",
    "            # Revised:\n",
    "            #  Take the CNN prediction IF it's probability is within 1 stddev of the corresponding GP class probability\n",
    "\n",
    "            # core idea: if CNN is _too_ sure then we revert to GP prediction -- might be adverserial...?\n",
    "\n",
    "            gp_prob_for_cnn_pred = mu[cnn_class]\n",
    "            gp_stddev_for_cnn_pred = np.sqrt(var[cnn_class])\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Models disagree on predicted class\")\n",
    "\n",
    "            if cnn_pred_prob < (gp_prob_for_cnn_pred + accept_cnn_stddev*gp_stddev_for_cnn_pred) \\\n",
    "               and cnn_pred_prob > (gp_pred_prob - accept_cnn_stddev*np.sqrt(gp_pred_var)):\n",
    "                if verbose:\n",
    "                    print(\"  Taking CNN prediction p=\", cnn_pred_prob, \", probability is within\", accept_cnn_stddev, \"stddev of GP probability p=\", gp_prob_for_cnn_pred)\n",
    "                decisions.append([1, cnn_class, cnn_pred_prob, -1])\n",
    "                decision_probs.append(cnn_probs)\n",
    "                decision_vars.append([-1 for x in range(mu.shape[-1])])\n",
    "\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"  Taking GP prediction\")\n",
    "                decisions.append([0, gp_class, gp_pred_prob, gp_pred_var])\n",
    "                decision_probs.append(mu)\n",
    "                decision_vars.append(var)\n",
    "    return (np.array(decisions), np.array(decision_probs), np.array(decision_vars))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Combined incorrect:  96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#combined_pred, combined_mus, combined_vars = combined_predict(cnn=mnist_cnn, gp=gp_model, images=mnist_test_full_reshape, accept_cnn_stddev=1.0)\n",
    "combined_pred, combined_mus, combined_vars = combined_predict_efficient(cnn_test_probs, mu, var, accept_cnn_stddev=1.0)\n",
    "combined_pred_classes = combined_pred[:, 1]\n",
    "combined_incorrect = combined_pred_classes != correct_classes\n",
    "print(\"Num Combined incorrect: \", np.count_nonzero(combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have all 3 of MNIST CNN, trained GP, and combined model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the N-MNIST data just like standard MNIST\n",
    "nmnist_noisy = scipy.io.loadmat('../data/raw/n-mnist/nmnist-awgn.mat')\n",
    "nmnist_blur = scipy.io.loadmat('../data/raw/n-mnist/nmnist-blur.mat')\n",
    "nmnist_noisy_lowcontrast = scipy.io.loadmat('../data/raw/n-mnist/nmnist-contrast.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import keras.utils\n",
    "\n",
    "def preprocess_mnist(xs, ys, one_hot_encode=-1):\n",
    "    img_rows, img_cols = 28, 28    \n",
    "    # reshape to inputs to correct shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        xs = xs.reshape(xs.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        xs = xs.reshape(xs.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    xs = xs.astype('float32')\n",
    "    xs /= 255\n",
    "    \n",
    "    if one_hot_encode != -1:\n",
    "        ys = keras.utils.to_categorical(ys, one_hot_encode) # one_hot_encode is the number of classes\n",
    "    \n",
    "    return (xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = K.function([mnist_cnn.layers[0].input, K.learning_phase()],\n",
    "                               [mnist_cnn.layers[6].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWGN: gp incorrect:  482\n",
      "AWGN: cnn incorrect:  462\n",
      "AWGN: combined incorrect:  461\n"
     ]
    }
   ],
   "source": [
    "# Process noisy mnist\n",
    "\n",
    "awgn_x_test, awgn_y_test = preprocess_mnist(nmnist_noisy['test_x'], nmnist_noisy['test_y'])\n",
    "awgn_features = feature_extractor([awgn_x_test, 0])[0]\n",
    "awgn_correct_classes = np.argmax(awgn_y_test, axis=1)\n",
    "\n",
    "awgn_gp_mu, awgn_gp_var = gp_model.predict_y(awgn_features)\n",
    "awgn_gp_preds = np.argmax(awgn_gp_mu, axis=1)\n",
    "awgn_gp_incorrect = awgn_gp_preds != awgn_correct_classes\n",
    "print(\"AWGN: gp incorrect: \", np.count_nonzero(awgn_gp_incorrect))\n",
    "\n",
    "awgn_cnn_probs = mnist_cnn.predict_on_batch(awgn_x_test)\n",
    "awgn_cnn_preds = np.argmax(awgn_cnn_probs, axis=1)\n",
    "awgn_cnn_incorrect = awgn_cnn_preds != awgn_correct_classes\n",
    "print(\"AWGN: cnn incorrect: \", np.count_nonzero(awgn_cnn_incorrect))\n",
    "\n",
    "awgn_combined_pred, awgn_combined_mus, awgn_combined_vars = combined_predict_efficient(awgn_cnn_probs, awgn_gp_mu, awgn_gp_var, accept_cnn_stddev=1.0)\n",
    "awgn_combined_pred_classes = awgn_combined_pred[:, 1]\n",
    "awgn_combined_incorrect = awgn_combined_pred_classes != awgn_correct_classes\n",
    "print(\"AWGN: combined incorrect: \", np.count_nonzero(awgn_combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blur: gp incorrect:  644\n",
      "Blur: cnn incorrect:  542\n",
      "Blur: combined incorrect:  555\n"
     ]
    }
   ],
   "source": [
    "# Process blurred mnist\n",
    "blur_x_test, blur_y_test = preprocess_mnist(nmnist_blur['test_x'], nmnist_blur['test_y'])\n",
    "blur_features = feature_extractor([blur_x_test, 0])[0]\n",
    "blur_correct_classes = np.argmax(blur_y_test, axis=1)\n",
    "\n",
    "blur_gp_mu, blur_gp_var = gp_model.predict_y(blur_features)\n",
    "blur_gp_preds = np.argmax(blur_gp_mu, axis=1)\n",
    "blur_gp_incorrect = blur_gp_preds != blur_correct_classes\n",
    "print(\"Blur: gp incorrect: \", np.count_nonzero(blur_gp_incorrect))\n",
    "\n",
    "blur_cnn_probs = mnist_cnn.predict_on_batch(blur_x_test)\n",
    "blur_cnn_preds = np.argmax(blur_cnn_probs, axis=1)\n",
    "blur_cnn_incorrect = blur_cnn_preds != blur_correct_classes\n",
    "print(\"Blur: cnn incorrect: \", np.count_nonzero(blur_cnn_incorrect))\n",
    "\n",
    "blur_combined_pred, blur_combined_mus, blur_combined_vars = combined_predict_efficient(blur_cnn_probs, blur_gp_mu, blur_gp_var, accept_cnn_stddev=1.0)\n",
    "blur_combined_pred_classes = blur_combined_pred[:, 1]\n",
    "blur_combined_incorrect = blur_combined_pred_classes != blur_correct_classes\n",
    "print(\"Blur: combined incorrect: \", np.count_nonzero(blur_combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcontrast: gp incorrect:  2158\n",
      "lcontrast: cnn incorrect:  2285\n"
     ]
    }
   ],
   "source": [
    "# Process low contrast mnist\n",
    "lcontrast_x_test, lcontrast_y_test = preprocess_mnist(nmnist_noisy_lowcontrast['test_x'], nmnist_noisy_lowcontrast['test_y'])\n",
    "lcontrast_features = feature_extractor([lcontrast_x_test, 0])[0]\n",
    "lcontrast_correct_classes = np.argmax(lcontrast_y_test, axis=1)\n",
    "\n",
    "lcontrast_gp_mu, lcontrast_gp_var = gp_model.predict_y(lcontrast_features)\n",
    "lcontrast_gp_preds = np.argmax(lcontrast_gp_mu, axis=1)\n",
    "lcontrast_gp_incorrect = lcontrast_gp_preds != lcontrast_correct_classes\n",
    "print(\"lcontrast: gp incorrect: \", np.count_nonzero(lcontrast_gp_incorrect))\n",
    "\n",
    "lcontrast_cnn_probs = mnist_cnn.predict_on_batch(lcontrast_x_test)\n",
    "lcontrast_cnn_preds = np.argmax(lcontrast_cnn_probs, axis=1)\n",
    "lcontrast_cnn_incorrect = lcontrast_cnn_preds != lcontrast_correct_classes\n",
    "print(\"lcontrast: cnn incorrect: \", np.count_nonzero(lcontrast_cnn_incorrect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcontrast: combined incorrect:  2154\n"
     ]
    }
   ],
   "source": [
    "lcontrast_combined_pred, lcontrast_combined_mus, lcontrast_combined_vars = combined_predict_efficient(lcontrast_cnn_probs, lcontrast_gp_mu, lcontrast_gp_var, accept_cnn_stddev=0.5, verbose=False)\n",
    "lcontrast_combined_pred_classes = lcontrast_combined_pred[:, 1]\n",
    "lcontrast_combined_incorrect = lcontrast_combined_pred_classes != lcontrast_correct_classes\n",
    "print(\"lcontrast: combined incorrect: \", np.count_nonzero(lcontrast_combined_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# best Matern12 results:\n",
    "AWGN: gp incorrect:  360\n",
    "AWGN: cnn incorrect:  462\n",
    "AWGN: combined incorrect:  424\n",
    "Blur: gp incorrect:  1254\n",
    "Blur: cnn incorrect:  542\n",
    "Blur: combined incorrect:  677\n",
    "lcontrast: gp incorrect:  2848\n",
    "lcontrast: cnn incorrect:  2285\n",
    "lcontrast: combined incorrect:  2880\n",
    "\n",
    "\n",
    "# best Matern32 results:\n",
    "AWGN: gp incorrect:  320\n",
    "AWGN: cnn incorrect:  462\n",
    "AWGN: combined incorrect:  382\n",
    "Blur: gp incorrect:  1280\n",
    "Blur: cnn incorrect:  542\n",
    "Blur: combined incorrect:  778\n",
    "lcontrast: gp incorrect:  4135\n",
    "lcontrast: cnn incorrect:  2285\n",
    "lcontrast: combined incorrect:  3058\n",
    "        \n",
    "# best Matern52 results:\n",
    "AWGN: gp incorrect:  388\n",
    "AWGN: cnn incorrect:  462\n",
    "AWGN: combined incorrect:  399\n",
    "Blur: gp incorrect:  1304\n",
    "Blur: cnn incorrect:  542\n",
    "Blur: combined incorrect:  856\n",
    "lcontrast: gp incorrect:  4809\n",
    "lcontrast: cnn incorrect:  2285\n",
    "lcontrast: combined incorrect:  3537\n",
    "\n",
    "# best Linear results:\n",
    "AWGN: gp incorrect:  438\n",
    "AWGN: cnn incorrect:  462\n",
    "AWGN: combined incorrect:  407\n",
    "Blur: gp incorrect:  2016\n",
    "Blur: cnn incorrect:  542\n",
    "Blur: combined incorrect:  1529\n",
    "lcontrast: gp incorrect:  5735\n",
    "lcontrast: cnn incorrect:  2285\n",
    "lcontrast: combined incorrect:  3887\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
