{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    " \n",
    "\n",
    "xs_train_full = np.genfromtxt(\"../data/mnist_train_features.csv\", delimiter=\",\")\n",
    "xs_test_full = np.genfromtxt(\"../data/mnist_test_features.csv\", delimiter=\",\")\n",
    "\n",
    "def get_mnist_classes():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return ((x_train, x_test), (y_train, y_test))\n",
    "\n",
    "((mnist_train_full, mnist_test_full), (ys_train_full, ys_test_full)) = get_mnist_classes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 128 features, predicting 10 classes\n"
     ]
    }
   ],
   "source": [
    "# fitting entirety of model on base MNIST data\n",
    "\n",
    "num_features = xs_train_full.shape[-1]\n",
    "num_classes = 10\n",
    "print(\"Using\", num_features, \"features, predicting\", num_classes, \"classes\")\n",
    "\n",
    "ys = np.argmax(ys_train_full, axis=1)\n",
    "\n",
    "full_model = gpflow.models.SVGP(\n",
    "    xs_train_full, ys, kern=gpflow.kernels.Matern32(input_dim=num_features) + gpflow.kernels.White(input_dim=num_features, variance=0.2),\n",
    "    likelihood=gpflow.likelihoods.MultiClass(num_classes),\n",
    "    Z=xs_train_full[::40].copy(), \n",
    "    num_latent=num_classes, \n",
    "    whiten=True, \n",
    "    q_diag=True,\n",
    "    minibatch_size=5000)\n",
    "full_model.kern.white.variance.trainable = False\n",
    "full_model.feature.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 6761.897608\n",
      "  Number of iterations: 16\n",
      "  Number of functions evaluations: 29\n"
     ]
    }
   ],
   "source": [
    "opt = gpflow.train.ScipyOptimizer()\n",
    "opt.minimize(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, var) = full_model.predict_y(xs_test_full)\n",
    "predicted_classes = np.argmax(mu, axis=1)\n",
    "correct_classes = np.argmax(ys_test_full, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full CNN\n",
    "mnist_cnn = keras.models.load_model('../models/mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    mnist_test_full = mnist_test_full.reshape(xs_test_full.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    mnist_test_full = mnist_test_full.reshape(xs_test_full.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "\n",
    "mnist_test_full = mnist_test_full.astype('float32')\n",
    "mnist_test_full /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_test_probs = mnist_cnn.predict_on_batch(mnist_test_full)\n",
    "cnn_test_preds = np.argmax(cnn_test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "\n",
    "\"\"\"\n",
    "params:\n",
    "    cnn: trained mnist CNN\n",
    "    gp: trained gaussian process for multiclass classification\n",
    "    verbose: printing on/off \n",
    "    accept_cnn_stddev: if CNN predicted class has higher prob than GP's, this is number of stddevs the CNN prediction needs to be within from the GP prediction to acccept it\n",
    "        ie. higher = more likely to revert to CNN!\n",
    "\"\"\"\n",
    "def combined_predict(cnn, gp, image, verbose=False, accept_cnn_stddev=1):\n",
    "    # so my CNN can only predict on batches of 4 or greater...\n",
    "    batch = np.array([image, image, image, image])\n",
    "    cnn_probs = cnn.predict_on_batch(batch)[0]\n",
    "    gp_mu, gp_var = gp.predict_y([image])\n",
    "    gp_mu, gp_var = gp_mu[0], gp_var[0]\n",
    "    \n",
    "    cnn_class = np.argmax(cnn_probs)\n",
    "    gp_class = np.argmax(gp_mu)\n",
    "    \n",
    "    # both classes agree\n",
    "    if gp_class == cnn_class:\n",
    "        # we may have to accept the wrong decision but can't do anything about it\n",
    "        if verbose:\n",
    "            print(\"Models agree on predicted class\")\n",
    "        return (0, gp_class, gp_mu, gp_var)\n",
    "        \n",
    "    else:\n",
    "        # disagreement! This is additional information\n",
    "        # From prior experiments we suspect that NN is more likely to be correct [non-adverserial examples tested]\n",
    "        # So, if we take the CNN prediction and check if it's the same as the _second_ highest GP prediction\n",
    "        # try using that?\n",
    "        \n",
    "        # Revised:\n",
    "        #  Take the CNN prediction IF it's probability is within 1 stddev of the corresponding GP class probability\n",
    "        \n",
    "        # core idea: if CNN is _too_ sure then we revert to GP prediction -- might be adverserial...?\n",
    "        \n",
    "        gp_prob_for_cnn_pred = gp_mu[cnn_class]\n",
    "        gp_stddev_for_cnn_pred = np.sqrt(gp_var[cnn_class])\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Models disagree on predicted class\")\n",
    "            \n",
    "        if cnn_pred_prob < (gp_prob_for_cnn_pred + accept_cnn_stddev*gp_stddev_for_cnn_pred):\n",
    "            if verbose:\n",
    "                print(\"  Taking CNN prediction, probability is within\", accept_cnn_stddev, \"stddev of GP probability\")\n",
    "            return (1, cnn_class, cnn_probs, [-1]*gp_var.shape[0])\n",
    "            \n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  Taking GP prediction\")\n",
    "            return (0, gp_class, gp_mu, gp_var)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have all 3 of MNIST CNN, trained GP, and combined model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b9ca83b21358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/raw/n-mnist/mnist-with-awgn.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Preprocess the N-MNIST data just like standard MNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/scratch/js2173/venv/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "\n",
    "\n",
    "# Preprocess the N-MNIST data just like standard MNIST\n",
    "nmnist_noisy = scipy.io.loadmat('../data/raw/n-mnist/mnist-with-awgn')\n",
    "nmnist_blur = scipy.io.loadmat('../data/raw/n-mnist/mnist-with-motion-blur')\n",
    "nmnist_noisy_lowcontrast = scipy.io.loadmat('../data/raw/n-mnist/mnist-with-reduced-contrast-and-awgn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
